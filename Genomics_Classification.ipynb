{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Genomics - Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qWYprsLLE62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "044e8bae-89e1-4ded-9bc0-3f0d4d1ed8f3"
      },
      "source": [
        "#@title Install prerequsite: you may have to do Runtime -> Restart runtime after the installation\n",
        "\n",
        "!pip install --upgrade \"mxnet<2.0.0\"\n",
        "!pip install botocore autogluon"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet<2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/bb/54cbabe428351c06d10903c658878d29ee7026efbe45133fd133598d6eb6/mxnet-1.7.0.post1-py2.py3-none-manylinux2014_x86_64.whl (55.0MB)\n",
            "\u001b[K     |████████████████████████████████| 55.0MB 74kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet<2.0.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet<2.0.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.7.0.post1\n",
            "Collecting botocore\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/6a/466d8644e61192e2b36db2aca2ebca952ad527220f9776b87e94de1a172d/botocore-1.19.14-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 4.3MB/s \n",
            "\u001b[?25hCollecting autogluon\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/51/ac91303a2eb3aa90e21056b42edcd1568fd8d971723600b3bc3868776107/autogluon-0.0.14-py3-none-any.whl (622kB)\n",
            "\u001b[K     |████████████████████████████████| 624kB 46.5MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore) (2.8.1)\n",
            "Collecting urllib3<1.26,>=1.25.4; python_version != \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<0.24,>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (0.22.2.post1)\n",
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.1MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/6e/ca243d7c15e46fa825be075ee0e57dd5c448121d6d00c9fb8702f665498d/boto3-1.16.14.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.8MB/s \n",
            "\u001b[?25hCollecting Pillow<=6.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/0e94e689de2476c4c5e644a3bd223a1c1b9e2bdb7c510191750be74fa786/Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 29.6MB/s \n",
            "\u001b[?25hCollecting fastparquet==0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b9/844e32d0e3739e5695057dff3a3b9f4abc0fcccff466fdaadb8fedb0ee1d/fastparquet-0.4.1.tar.gz (28.6MB)\n",
            "\u001b[K     |████████████████████████████████| 28.6MB 151kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.6/dist-packages (from autogluon) (2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from autogluon) (2.23.0)\n",
            "Collecting openml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/5d/30ce4d1af609ba389d55654e6a7271619253dbbe7006a33bb20c703f0234/openml-0.11.0.tar.gz (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<=1.0.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (0.14.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from autogluon) (0.8.4)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (4.41.1)\n",
            "Collecting ConfigSpace<=0.4.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/de/4e8e4f26332fc65404f52baa112defbf822b6738b60bfa6b2993f5c60933/ConfigSpace-0.4.10.tar.gz (882kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.0MB/s \n",
            "\u001b[?25hCollecting gluoncv<1.0,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/d7/74b530c461ac3eb90f6045a645a59450de1f3d616a4926e371daa021dbd8/gluoncv-0.8.0-py2.py3-none-any.whl (810kB)\n",
            "\u001b[K     |████████████████████████████████| 819kB 36.3MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a2/6565c5271a79e3c96d7a079053b4d8408a740d4bf365f0f5f244a807bd09/cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 48.1MB/s \n",
            "\u001b[?25hCollecting distributed>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/38/d9f0e31c15de18cb124d1ed33cf9c99c84f05f251ff6767e7573c217725b/distributed-2.30.1-py3-none-any.whl (656kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 36.7MB/s \n",
            "\u001b[?25hCollecting paramiko>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from autogluon) (3.2.2)\n",
            "Collecting catboost<0.25,>=0.23.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/39/128fff65072c8327371e3c594f3c826d29c85b21cb6485980353b168e0e4/catboost-0.24.2-cp36-none-manylinux1_x86_64.whl (66.1MB)\n",
            "\u001b[K     |████████████████████████████████| 66.2MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from autogluon) (3.6.4)\n",
            "Collecting lightgbm<4.0,>=3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/47/f8ef524e15ff86f5246cb4e1cee200b747ddb2536429fa021cc5f17ea40a/lightgbm-3.0.0-py2.py3-none-manylinux1_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 45.3MB/s \n",
            "\u001b[?25hCollecting autogluon-contrib-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/dc/30d76d44709cf87e9ae9bc9ed8c9ce1882436427ded27edced390ed2933f/autogluon_contrib_nlp-0.0.1b20201009-py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.6/dist-packages (from autogluon) (5.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from autogluon) (1.4.1)\n",
            "Requirement already satisfied: psutil<=5.7.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (1.18.5)\n",
            "Requirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (2.12.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from autogluon) (0.29.21)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (1.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.24,>=0.22.0->autogluon) (0.17.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.28 in /usr/local/lib/python3.6/dist-packages (from fastparquet==0.4.1->autogluon) (0.48.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastparquet==0.4.1->autogluon) (20.4)\n",
            "Collecting thrift>=0.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/1e/3284d19d7be99305eda145b8aa46b0c33244e4a496ec66440dac19f8274d/thrift-0.13.0.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx<3.0,>=2.3->autogluon) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->autogluon) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->autogluon) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->autogluon) (3.0.4)\n",
            "Collecting liac-arff>=2.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/43/73944aa5ad2b3185c0f0ba0ee6f73277f2eb51782ca6ccf3e6793caf209a/liac-arff-2.5.0.tar.gz\n",
            "Collecting xmltodict\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<=0.4.10->autogluon) (2.4.7)\n",
            "Collecting typing\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/d9/6eebe19d46bd05360c9a9aae822e67a80f9242aabbfc58b641b957546607/typing-3.7.4.3.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->autogluon) (1.14.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (2.0.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (1.7.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (0.11.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (50.3.2)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (7.1.2)\n",
            "Collecting contextvars; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (3.13)\n",
            "Collecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->autogluon) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->autogluon) (0.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost<0.25,>=0.23.0->autogluon) (4.4.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (8.6.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (20.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (1.9.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from autogluon-contrib-nlp->autogluon) (2019.12.20)\n",
            "Collecting tokenizers<0.9.0,>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ee/fedc3509145ad60fe5b418783f4a4c1b5462a4f0e8c7bbdbda52bdcda486/tokenizers-0.8.1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 38.3MB/s \n",
            "\u001b[?25hCollecting sacremoses>=0.0.38\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.0MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[?25hCollecting flake8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ca/3971802ee6251da1abead1a22831d7f4743781e2f743bd266bdd2f46c19b/flake8-3.8.4-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from autogluon-contrib-nlp->autogluon) (3.12.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas<2.0,>=1.0.0->autogluon) (2018.9)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.28->fastparquet==0.4.1->autogluon) (0.31.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->autogluon) (2.20)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.6/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon) (1.0.1)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost<0.25,>=0.23.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from flake8->autogluon-contrib-nlp->autogluon) (2.0.0)\n",
            "Collecting pycodestyle<2.7.0,>=2.6.0a1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hCollecting pyflakes<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/5b/fd01b0c696f2f9a6d2c839883b642493b431f28fa32b29abc465ef675473/pyflakes-2.2.0-py2.py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->flake8->autogluon-contrib-nlp->autogluon) (3.4.0)\n",
            "Building wheels for collected packages: boto3, fastparquet, openml, ConfigSpace, thrift, liac-arff, typing, contextvars, sacremoses\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.16.14-py2.py3-none-any.whl size=128454 sha256=6c86fa2a463250c00100912110844e0f5ec7f8a943ca18cba2d356545b22a215\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/96/69/8594285f4630ffa8773252514c65929484410e38bd6604629e\n",
            "  Building wheel for fastparquet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastparquet: filename=fastparquet-0.4.1-cp36-cp36m-linux_x86_64.whl size=7125489 sha256=0dd1705ce4fdedd025279e3618f301b4a58fc94cb2cf6cd4e262e3e23065600c\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/45/cf/492ccb908adde1dd2551bb509a56e4096cce9487167f525120\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.11.0-cp36-none-any.whl size=127467 sha256=8e59e54e508fc410c7caa8b071bb38e9e6b5d62e9299cdfa36398977ba7c708e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/29/f1/58115101bafad19069e838060ab6bdd8046abceba508500e03\n",
            "  Building wheel for ConfigSpace (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.10-cp36-cp36m-linux_x86_64.whl size=2712246 sha256=2cb387481929e4186b521b7071c315446f558eaa6fb509115c6b495c696399e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/83/cb/28dd42bac69c8867d485138030daa83841c7f84afe68b2fdf7\n",
            "  Building wheel for thrift (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=345215 sha256=03df9d409e395b44fcb2758d8c8c2c90dcd68b06f7c2c04e29d23d206b2ed471\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/a2/46/689ccfcf40155c23edc7cdbd9de488611c8fdf49ff34b1706e\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-cp36-none-any.whl size=11734 sha256=4487422ffc31391ceb112c38380a7355a7e2c1927382769b0ea08ba1c94907c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/8d/b4/8bfce5beea9a3496cc15b24961876adb7b6e2912ff09164179\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-cp36-none-any.whl size=26307 sha256=2df1b46860ab1cc114bf94bd28eed1e7a4b48986c8fdad1f4844713c1c5d9f45\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/04/41/8e1836e79581989c22eebac3f4e70aaac9af07b0908da173be\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=66e785430cca24bc3db6d09180db4e1e27ffc4893392682f0bda57c1619885a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=af25f83e159951aaa437c82f75fe08b020678cc3aaa656f6c127fefda23739d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built boto3 fastparquet openml ConfigSpace thrift liac-arff typing contextvars sacremoses\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement cloudpickle==1.3, but you'll have cloudpickle 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, urllib3, botocore, pyaml, scikit-optimize, s3transfer, boto3, Pillow, thrift, fastparquet, liac-arff, xmltodict, openml, typing, ConfigSpace, portalocker, gluoncv, cryptography, cloudpickle, immutables, contextvars, distributed, bcrypt, pynacl, paramiko, catboost, lightgbm, yacs, tokenizers, sacremoses, sacrebleu, pycodestyle, pyflakes, mccabe, flake8, sentencepiece, autogluon-contrib-nlp, autogluon\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed ConfigSpace-0.4.10 Pillow-6.2.1 autogluon-0.0.14 autogluon-contrib-nlp-0.0.1b20201009 bcrypt-3.2.0 boto3-1.16.14 botocore-1.19.14 catboost-0.24.2 cloudpickle-1.6.0 contextvars-2.4 cryptography-3.2.1 distributed-2.30.1 fastparquet-0.4.1 flake8-3.8.4 gluoncv-0.8.0 immutables-0.14 jmespath-0.10.0 liac-arff-2.5.0 lightgbm-3.0.0 mccabe-0.6.1 openml-0.11.0 paramiko-2.7.2 portalocker-2.0.0 pyaml-20.4.0 pycodestyle-2.6.0 pyflakes-2.2.0 pynacl-1.4.0 s3transfer-0.3.3 sacrebleu-1.4.14 sacremoses-0.0.43 scikit-optimize-0.8.1 sentencepiece-0.1.94 thrift-0.13.0 tokenizers-0.8.1 typing-3.7.4.3 urllib3-1.25.11 xmltodict-0.12.0 yacs-0.1.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "typing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZB6H1c98rEF"
      },
      "source": [
        "# try out if you can load autogluon ok, if not, try restart your runtime and \n",
        "# redo the installation\n",
        "\n",
        "import autogluon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_mQlXl4BnDA",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aeb78cd-a47c-46d1-9798-78f152e24b51"
      },
      "source": [
        "#@title Mount Google Drive (You don't need to run this if you are running notebooks on your laptop)\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# The following command will prompt a URL for you to click and obtain the\n",
        "# authorization code\n",
        "\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQD4mkx-CCmA"
      },
      "source": [
        "# Set up data folder\n",
        "from pathlib import Path\n",
        "\n",
        "# Change this to where you put your hw2 files\n",
        "DATA = Path(\"/content/drive/My Drive/Colab Notebooks/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEpLQx3tR08M"
      },
      "source": [
        "# Assignment: Classification and Characterization of Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVpMokdnR08U"
      },
      "source": [
        "## Classifying COVID-19 infection using AutoML\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCIkTJEDlwnN"
      },
      "source": [
        "We have done differential expression between COVID-19 vs other viral and non-viral acute respiratory illnesses (ARIs) in Problem 1, HW2A. As we see a distinct transcriptomic pattern in COVID-19 infected samples, we will try to build a binary classification model, that given an transcriptomic profile of an upper airway sample, the model can predict whether this sample is infected by COVID-19 or not.\n",
        "\n",
        "I will use use the log2 CPM values generated from DGEList to build the model, with data: [ua_gse156063_cpm.txt](https://drive.google.com/file/d/1XJwvrxuBCsk8pne4ByGGPfeHmBF86ri8/view?usp=sharing)\n",
        "\n",
        "Meta data is loaded, and then I extract sample IDs that match the column names of the expression table as the first 12 characters in the sample title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TCbmVGlXQNa"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "gefile = DATA / \"ua_gse156063_cpm.txt\"\n",
        "metafile = DATA / \"GSE156063_characteristics.txt\"\n",
        "\n",
        "ge = pd.read_csv(gefile, sep=\"\\t\", index_col=0)\n",
        "meta = pd.read_csv(metafile, sep=\"\\t\")\n",
        "meta[\"sample_id\"] = meta.sample_title.str[:12]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwmuAehrsTR3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "e8043c11-5389-4828-fda5-2d081a33546e"
      },
      "source": [
        "meta.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_title</th>\n",
              "      <th>sars-cov-2_pcr</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>geo_accession</th>\n",
              "      <th>disease_state</th>\n",
              "      <th>sars-cov-2_rpm</th>\n",
              "      <th>sample_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RR057e_00253_M12_S189</td>\n",
              "      <td>0.041795</td>\n",
              "      <td>M</td>\n",
              "      <td>51.0</td>\n",
              "      <td>GSM4721600</td>\n",
              "      <td>other virus</td>\n",
              "      <td>NEG</td>\n",
              "      <td>RR057e_00253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RR057e_00231_K12_S187</td>\n",
              "      <td>0.294782</td>\n",
              "      <td>F</td>\n",
              "      <td>44.0</td>\n",
              "      <td>GSM4721707</td>\n",
              "      <td>no virus</td>\n",
              "      <td>NEG</td>\n",
              "      <td>RR057e_00231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RR057e_00508_C04_S51</td>\n",
              "      <td>0.094097</td>\n",
              "      <td>M</td>\n",
              "      <td>49.0</td>\n",
              "      <td>GSM4721665</td>\n",
              "      <td>no virus</td>\n",
              "      <td>NEG</td>\n",
              "      <td>RR057e_00508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RR057i_00157_D15_S228</td>\n",
              "      <td>889882.176583</td>\n",
              "      <td>F</td>\n",
              "      <td>76.0</td>\n",
              "      <td>GSM4721596</td>\n",
              "      <td>SC2</td>\n",
              "      <td>POS</td>\n",
              "      <td>RR057i_00157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RR057e_00427_I08_S121</td>\n",
              "      <td>0.071005</td>\n",
              "      <td>F</td>\n",
              "      <td>67.0</td>\n",
              "      <td>GSM4721702</td>\n",
              "      <td>other virus</td>\n",
              "      <td>NEG</td>\n",
              "      <td>RR057e_00427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            sample_title  sars-cov-2_pcr  ... sars-cov-2_rpm     sample_id\n",
              "0  RR057e_00253_M12_S189        0.041795  ...            NEG  RR057e_00253\n",
              "1  RR057e_00231_K12_S187        0.294782  ...            NEG  RR057e_00231\n",
              "2   RR057e_00508_C04_S51        0.094097  ...            NEG  RR057e_00508\n",
              "3  RR057i_00157_D15_S228   889882.176583  ...            POS  RR057i_00157\n",
              "4  RR057e_00427_I08_S121        0.071005  ...            NEG  RR057e_00427\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1lsZi1xZgRM"
      },
      "source": [
        "Let's see how samples we have per each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygPWOUr_ZsZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5385ea-3809-4145-cc52-ced47830168f"
      },
      "source": [
        "meta.groupby(\"disease_state\").sample_id.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "disease_state\n",
              "SC2             93\n",
              "no virus       100\n",
              "other virus     41\n",
              "Name: sample_id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtRVGnInZx-q"
      },
      "source": [
        "### Split test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk670ue7Z0YZ"
      },
      "source": [
        "Now is the definition of the test set to be held out from model building process. Given that there are much fewer samples in `other virus` class, it would not be reasonable to enforce having equal number in each class in training set. Instead, I will sample equal proportion from each class as training and testing.\n",
        "\n",
        "For this, I will pick 20% of each class as the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAY6bUqGYFzF"
      },
      "source": [
        "import numpy as np\n",
        "# set the seed to ensure reproducibility\n",
        "np.random.seed(4060)\n",
        "# from each class pick 20% of the samples as test set\n",
        "test_samples = meta.groupby(\"disease_state\").apply(\n",
        "    lambda x: x.sample(frac=0.2)\n",
        ").sample_id.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui84gx5sZBdh"
      },
      "source": [
        "# define train and test set\n",
        "meta[\"subset\"] = \"train\"\n",
        "meta.loc[meta.sample_id.isin(test_samples), \"subset\"] = \"test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mD1x5a1dUam"
      },
      "source": [
        "As a sanity check, let's see how many samples we have in each class after the split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBpq7fQAbbR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f373b6c8-1e19-4f6b-c7be-3b2c03f8b9d0"
      },
      "source": [
        "meta.groupby([\"subset\", \"disease_state\"]).sample_id.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subset  disease_state\n",
              "test    SC2              19\n",
              "        no virus         20\n",
              "        other virus       8\n",
              "train   SC2              74\n",
              "        no virus         80\n",
              "        other virus      33\n",
              "Name: sample_id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRsfR-hnfBTI"
      },
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LjjwB2S__xE"
      },
      "source": [
        "Similar to what was done in class - feature selection using `MultiTaskLassoCV` for building a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K471tRCDLHhv"
      },
      "source": [
        "#=================================================\n",
        "# Your code here\n",
        "# Perform feature selection using MultiTaskLassoCV\n",
        "from sklearn.linear_model import MultiTaskLassoCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKAWgr7MsmJ0"
      },
      "source": [
        "# OHE matrix\n",
        "encoder = OneHotEncoder()\n",
        "target = encoder.fit_transform(meta[[\"disease_state\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDCxWjTesmRL"
      },
      "source": [
        "# Training and Testing Data\n",
        "x_train = ge[meta[meta.subset == \"train\"].sample_id].transpose()\n",
        "y_train = target[(meta.subset == \"train\").values].toarray()\n",
        "x_test = ge[meta[meta.subset == \"test\"].sample_id].transpose()\n",
        "y_test = target[(meta.subset == \"test\").values].toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR5Q-g3etVDV"
      },
      "source": [
        "# Perform MultiTaskLassoCV\n",
        "lassocv = MultiTaskLassoCV().fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSqAedr-QR3k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "024a1e43-8469-4b07-aef6-283c22bca256"
      },
      "source": [
        "pd.DataFrame(lassocv.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>15453</th>\n",
              "      <th>15454</th>\n",
              "      <th>15455</th>\n",
              "      <th>15456</th>\n",
              "      <th>15457</th>\n",
              "      <th>15458</th>\n",
              "      <th>15459</th>\n",
              "      <th>15460</th>\n",
              "      <th>15461</th>\n",
              "      <th>15462</th>\n",
              "      <th>15463</th>\n",
              "      <th>15464</th>\n",
              "      <th>15465</th>\n",
              "      <th>15466</th>\n",
              "      <th>15467</th>\n",
              "      <th>15468</th>\n",
              "      <th>15469</th>\n",
              "      <th>15470</th>\n",
              "      <th>15471</th>\n",
              "      <th>15472</th>\n",
              "      <th>15473</th>\n",
              "      <th>15474</th>\n",
              "      <th>15475</th>\n",
              "      <th>15476</th>\n",
              "      <th>15477</th>\n",
              "      <th>15478</th>\n",
              "      <th>15479</th>\n",
              "      <th>15480</th>\n",
              "      <th>15481</th>\n",
              "      <th>15482</th>\n",
              "      <th>15483</th>\n",
              "      <th>15484</th>\n",
              "      <th>15485</th>\n",
              "      <th>15486</th>\n",
              "      <th>15487</th>\n",
              "      <th>15488</th>\n",
              "      <th>15489</th>\n",
              "      <th>15490</th>\n",
              "      <th>15491</th>\n",
              "      <th>15492</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 15493 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0      1      2      3      4      ...  15488  15489  15490  15491  15492\n",
              "0    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "1    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "2    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "\n",
              "[3 rows x 15493 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THGIAD9W9vxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708d23ad-341c-408a-9fc7-606730db5267"
      },
      "source": [
        "# count how many genes was selected across all disease states\n",
        "\n",
        "((lassocv.coef_ != 0).sum(axis=0) != 0).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgl_gXbU92U5"
      },
      "source": [
        "From the above function, we can see that 80 genes were selected by the Lasso models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHN3LNgm9t-H"
      },
      "source": [
        "#### Genes selected by the Lasso models are entered into the [MSigDB website](https://www.gsea-msigdb.org/gsea/msigdb/annotate.jsp). Options chosen are `H: hallmark gene sets`, `C2: curated gene sets`, and `C7: immunologic signature gene sets`, and leave the rest as default. Among the gene sets reported to be enriched, are there any gene sets you find that are related to respiratory system / diseases?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxLQU_cczkGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9521e42-55fa-4096-be67-bc50414a5f31"
      },
      "source": [
        "lassocv.coef_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 15493)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDB24vU5XJZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eeaadd2-2f17-463c-ae11-4bdf5049b258"
      },
      "source": [
        "lasso_selections = np.where((lassocv.coef_ != 0).sum(axis=0) > 0)\n",
        "lasso_selections"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  253,   506,  1209,  1317,  1770,  1803,  1995,  2079,  2152,\n",
              "         2209,  2380,  2658,  2698,  2992,  3054,  3211,  3212,  3526,\n",
              "         3816,  3831,  3930,  4042,  4281,  4291,  4427,  4681,  4874,\n",
              "         5213,  5309,  5321,  5401,  5474,  5519,  5524,  5589,  5609,\n",
              "         5641,  5845,  6047,  6077,  6085,  6140,  6165,  6528,  6543,\n",
              "         6730,  6970,  6974,  7003,  7079,  7359,  7602,  7779,  7865,\n",
              "         7968,  8097,  8109,  8175,  8721,  9104,  9309,  9362,  9424,\n",
              "        10841, 10873, 10914, 10915, 11427, 11820, 11988, 12477, 12695,\n",
              "        13211, 13434, 13602, 13686, 13910, 14407, 14606, 14905]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU77I2x7zq23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "60a928ae-e9dc-4f4e-c798-c741a9dfb26b"
      },
      "source": [
        "ge.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RR057e_00253</th>\n",
              "      <th>RR057e_00231</th>\n",
              "      <th>RR057e_00508</th>\n",
              "      <th>RR057i_00157</th>\n",
              "      <th>RR057e_00427</th>\n",
              "      <th>RR057e_00741</th>\n",
              "      <th>RR057e_00586</th>\n",
              "      <th>RR057e_00549</th>\n",
              "      <th>RR057e_00504</th>\n",
              "      <th>RR057e_00401</th>\n",
              "      <th>RR057i_00064</th>\n",
              "      <th>RR057e_00239</th>\n",
              "      <th>RR057e_00488</th>\n",
              "      <th>RR057e_00727</th>\n",
              "      <th>RR057e_00268</th>\n",
              "      <th>RR057e_00759</th>\n",
              "      <th>RR057e_00748</th>\n",
              "      <th>RR057e_00107</th>\n",
              "      <th>RR057i_00137</th>\n",
              "      <th>RR057e_00119</th>\n",
              "      <th>RR057i_00062</th>\n",
              "      <th>RR057i_00120</th>\n",
              "      <th>RR057e_00726</th>\n",
              "      <th>RR057i_00131</th>\n",
              "      <th>RR057e_00161</th>\n",
              "      <th>RR057i_00081</th>\n",
              "      <th>RR057e_00224</th>\n",
              "      <th>RR057e_00515</th>\n",
              "      <th>RR057e_00505</th>\n",
              "      <th>RR057e_00733</th>\n",
              "      <th>RR057e_00051</th>\n",
              "      <th>RR057e_00088</th>\n",
              "      <th>RR057e_00744</th>\n",
              "      <th>RR057e_00076</th>\n",
              "      <th>RR057i_00163</th>\n",
              "      <th>RR057i_00080</th>\n",
              "      <th>RR057e_00074</th>\n",
              "      <th>RR057e_00168</th>\n",
              "      <th>RR057e_00491</th>\n",
              "      <th>RR057e_00206</th>\n",
              "      <th>...</th>\n",
              "      <th>RR057e_00743</th>\n",
              "      <th>RR057e_00752</th>\n",
              "      <th>RR057e_00454</th>\n",
              "      <th>RR057e_00130</th>\n",
              "      <th>RR057e_00516</th>\n",
              "      <th>RR057e_00577</th>\n",
              "      <th>RR057e_00142</th>\n",
              "      <th>RR057i_00098</th>\n",
              "      <th>RR057e_00080</th>\n",
              "      <th>RR057i_00180</th>\n",
              "      <th>RR057e_00440</th>\n",
              "      <th>RR057e_00260</th>\n",
              "      <th>RR057e_00747</th>\n",
              "      <th>RR057e_00399</th>\n",
              "      <th>RR057e_00073</th>\n",
              "      <th>RR057e_00324</th>\n",
              "      <th>RR057i_00104</th>\n",
              "      <th>RR057e_00309</th>\n",
              "      <th>RR057i_00075</th>\n",
              "      <th>RR057i_00086</th>\n",
              "      <th>RR057i_00094</th>\n",
              "      <th>RR057e_00294</th>\n",
              "      <th>RR057i_00108</th>\n",
              "      <th>RR057i_00106</th>\n",
              "      <th>RR057e_00039</th>\n",
              "      <th>RR057e_00273</th>\n",
              "      <th>RR057i_00158</th>\n",
              "      <th>RR057e_00494</th>\n",
              "      <th>RR057i_00095</th>\n",
              "      <th>RR057e_00203</th>\n",
              "      <th>RR057e_00216</th>\n",
              "      <th>RR057e_00202</th>\n",
              "      <th>RR057i_00114</th>\n",
              "      <th>RR057e_00761</th>\n",
              "      <th>RR057i_00096</th>\n",
              "      <th>RR057e_00736</th>\n",
              "      <th>RR057i_00072</th>\n",
              "      <th>RR057i_00175</th>\n",
              "      <th>RR057e_00116</th>\n",
              "      <th>RR057i_00078</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A1BG</th>\n",
              "      <td>3.3895</td>\n",
              "      <td>4.3247</td>\n",
              "      <td>1.0815</td>\n",
              "      <td>2.6302</td>\n",
              "      <td>3.4676</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>3.0835</td>\n",
              "      <td>0.7981</td>\n",
              "      <td>1.3385</td>\n",
              "      <td>3.1307</td>\n",
              "      <td>0.8569</td>\n",
              "      <td>3.5388</td>\n",
              "      <td>3.3830</td>\n",
              "      <td>2.7075</td>\n",
              "      <td>-0.0622</td>\n",
              "      <td>3.6461</td>\n",
              "      <td>3.2491</td>\n",
              "      <td>3.0845</td>\n",
              "      <td>4.2962</td>\n",
              "      <td>5.1269</td>\n",
              "      <td>0.9919</td>\n",
              "      <td>1.7798</td>\n",
              "      <td>3.0217</td>\n",
              "      <td>3.6693</td>\n",
              "      <td>4.4358</td>\n",
              "      <td>2.7666</td>\n",
              "      <td>4.3443</td>\n",
              "      <td>2.7554</td>\n",
              "      <td>4.1754</td>\n",
              "      <td>-0.5479</td>\n",
              "      <td>2.8551</td>\n",
              "      <td>2.3095</td>\n",
              "      <td>2.6260</td>\n",
              "      <td>3.2932</td>\n",
              "      <td>3.2947</td>\n",
              "      <td>4.1572</td>\n",
              "      <td>3.2185</td>\n",
              "      <td>3.6714</td>\n",
              "      <td>3.8747</td>\n",
              "      <td>1.9102</td>\n",
              "      <td>...</td>\n",
              "      <td>3.1500</td>\n",
              "      <td>3.4603</td>\n",
              "      <td>4.0349</td>\n",
              "      <td>2.7085</td>\n",
              "      <td>3.6635</td>\n",
              "      <td>3.4693</td>\n",
              "      <td>3.9488</td>\n",
              "      <td>3.3948</td>\n",
              "      <td>3.9321</td>\n",
              "      <td>3.6004</td>\n",
              "      <td>3.2452</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>3.7239</td>\n",
              "      <td>3.3997</td>\n",
              "      <td>2.2276</td>\n",
              "      <td>0.7066</td>\n",
              "      <td>2.8015</td>\n",
              "      <td>2.9130</td>\n",
              "      <td>3.0769</td>\n",
              "      <td>2.7666</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>3.7441</td>\n",
              "      <td>1.8251</td>\n",
              "      <td>2.9678</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>3.0391</td>\n",
              "      <td>3.2190</td>\n",
              "      <td>3.8771</td>\n",
              "      <td>3.2567</td>\n",
              "      <td>4.3627</td>\n",
              "      <td>4.3345</td>\n",
              "      <td>3.2783</td>\n",
              "      <td>2.3835</td>\n",
              "      <td>3.4034</td>\n",
              "      <td>3.0224</td>\n",
              "      <td>3.6202</td>\n",
              "      <td>2.9906</td>\n",
              "      <td>2.3771</td>\n",
              "      <td>2.7813</td>\n",
              "      <td>3.0524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A1CF</th>\n",
              "      <td>1.7220</td>\n",
              "      <td>2.6350</td>\n",
              "      <td>2.9033</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>1.1702</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>1.1125</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>2.2564</td>\n",
              "      <td>1.7255</td>\n",
              "      <td>1.3893</td>\n",
              "      <td>0.4455</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>1.4866</td>\n",
              "      <td>0.2909</td>\n",
              "      <td>2.9640</td>\n",
              "      <td>1.2180</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>3.8800</td>\n",
              "      <td>-0.2423</td>\n",
              "      <td>1.7240</td>\n",
              "      <td>1.0693</td>\n",
              "      <td>2.6470</td>\n",
              "      <td>0.6612</td>\n",
              "      <td>2.6953</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>2.7498</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>1.3333</td>\n",
              "      <td>1.0204</td>\n",
              "      <td>1.1022</td>\n",
              "      <td>1.8363</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>1.5165</td>\n",
              "      <td>1.7550</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5483</td>\n",
              "      <td>1.0869</td>\n",
              "      <td>2.2354</td>\n",
              "      <td>1.9928</td>\n",
              "      <td>2.2351</td>\n",
              "      <td>1.0531</td>\n",
              "      <td>1.8114</td>\n",
              "      <td>0.8347</td>\n",
              "      <td>2.2964</td>\n",
              "      <td>0.9675</td>\n",
              "      <td>0.8239</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>0.6604</td>\n",
              "      <td>2.3294</td>\n",
              "      <td>1.4582</td>\n",
              "      <td>2.0841</td>\n",
              "      <td>0.5211</td>\n",
              "      <td>1.0900</td>\n",
              "      <td>2.5658</td>\n",
              "      <td>1.6606</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>-1.4078</td>\n",
              "      <td>2.7568</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>2.2364</td>\n",
              "      <td>2.2689</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.2226</td>\n",
              "      <td>4.2100</td>\n",
              "      <td>1.5724</td>\n",
              "      <td>1.5619</td>\n",
              "      <td>1.4384</td>\n",
              "      <td>2.1888</td>\n",
              "      <td>0.2560</td>\n",
              "      <td>1.5425</td>\n",
              "      <td>1.4511</td>\n",
              "      <td>1.9191</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>1.2718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2M</th>\n",
              "      <td>5.5584</td>\n",
              "      <td>5.0045</td>\n",
              "      <td>5.6555</td>\n",
              "      <td>4.9819</td>\n",
              "      <td>4.7248</td>\n",
              "      <td>5.2409</td>\n",
              "      <td>6.2807</td>\n",
              "      <td>6.9811</td>\n",
              "      <td>4.6170</td>\n",
              "      <td>5.7709</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>6.1807</td>\n",
              "      <td>4.8850</td>\n",
              "      <td>5.0625</td>\n",
              "      <td>5.3453</td>\n",
              "      <td>6.7780</td>\n",
              "      <td>6.0478</td>\n",
              "      <td>5.2367</td>\n",
              "      <td>5.5430</td>\n",
              "      <td>8.5940</td>\n",
              "      <td>5.4434</td>\n",
              "      <td>5.1509</td>\n",
              "      <td>4.6098</td>\n",
              "      <td>5.9728</td>\n",
              "      <td>4.2231</td>\n",
              "      <td>6.2273</td>\n",
              "      <td>4.9287</td>\n",
              "      <td>7.7823</td>\n",
              "      <td>6.0200</td>\n",
              "      <td>6.0182</td>\n",
              "      <td>6.1870</td>\n",
              "      <td>5.5898</td>\n",
              "      <td>4.9968</td>\n",
              "      <td>4.5932</td>\n",
              "      <td>3.5401</td>\n",
              "      <td>5.0899</td>\n",
              "      <td>3.7864</td>\n",
              "      <td>3.8340</td>\n",
              "      <td>4.8703</td>\n",
              "      <td>6.2279</td>\n",
              "      <td>...</td>\n",
              "      <td>6.2978</td>\n",
              "      <td>4.6253</td>\n",
              "      <td>5.1045</td>\n",
              "      <td>5.4036</td>\n",
              "      <td>5.2027</td>\n",
              "      <td>4.2168</td>\n",
              "      <td>3.4508</td>\n",
              "      <td>4.0304</td>\n",
              "      <td>5.0513</td>\n",
              "      <td>4.1625</td>\n",
              "      <td>4.4165</td>\n",
              "      <td>3.1628</td>\n",
              "      <td>6.4946</td>\n",
              "      <td>4.2466</td>\n",
              "      <td>6.3597</td>\n",
              "      <td>4.4056</td>\n",
              "      <td>3.7672</td>\n",
              "      <td>4.1968</td>\n",
              "      <td>4.5909</td>\n",
              "      <td>4.2595</td>\n",
              "      <td>6.6551</td>\n",
              "      <td>5.0033</td>\n",
              "      <td>1.8251</td>\n",
              "      <td>5.1672</td>\n",
              "      <td>5.8661</td>\n",
              "      <td>2.4826</td>\n",
              "      <td>5.2330</td>\n",
              "      <td>4.3727</td>\n",
              "      <td>3.5940</td>\n",
              "      <td>4.2100</td>\n",
              "      <td>4.6706</td>\n",
              "      <td>6.1359</td>\n",
              "      <td>4.8029</td>\n",
              "      <td>5.0247</td>\n",
              "      <td>4.6698</td>\n",
              "      <td>3.6644</td>\n",
              "      <td>4.4139</td>\n",
              "      <td>4.6516</td>\n",
              "      <td>5.6167</td>\n",
              "      <td>5.1468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2ML1</th>\n",
              "      <td>2.9553</td>\n",
              "      <td>4.1445</td>\n",
              "      <td>3.2126</td>\n",
              "      <td>1.1905</td>\n",
              "      <td>4.2413</td>\n",
              "      <td>2.1492</td>\n",
              "      <td>7.3150</td>\n",
              "      <td>3.4099</td>\n",
              "      <td>5.5407</td>\n",
              "      <td>4.2304</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>2.6623</td>\n",
              "      <td>2.8999</td>\n",
              "      <td>4.6222</td>\n",
              "      <td>-0.0622</td>\n",
              "      <td>3.4207</td>\n",
              "      <td>2.7700</td>\n",
              "      <td>2.8998</td>\n",
              "      <td>3.1410</td>\n",
              "      <td>2.6289</td>\n",
              "      <td>5.2680</td>\n",
              "      <td>5.3100</td>\n",
              "      <td>4.5674</td>\n",
              "      <td>3.1986</td>\n",
              "      <td>5.2821</td>\n",
              "      <td>3.0474</td>\n",
              "      <td>9.4634</td>\n",
              "      <td>6.6325</td>\n",
              "      <td>5.3177</td>\n",
              "      <td>-0.5479</td>\n",
              "      <td>3.3586</td>\n",
              "      <td>5.5429</td>\n",
              "      <td>3.6723</td>\n",
              "      <td>5.0393</td>\n",
              "      <td>3.1544</td>\n",
              "      <td>6.0409</td>\n",
              "      <td>4.0697</td>\n",
              "      <td>3.5362</td>\n",
              "      <td>4.1996</td>\n",
              "      <td>4.8822</td>\n",
              "      <td>...</td>\n",
              "      <td>3.3315</td>\n",
              "      <td>3.3517</td>\n",
              "      <td>2.5065</td>\n",
              "      <td>7.0302</td>\n",
              "      <td>6.4670</td>\n",
              "      <td>2.7962</td>\n",
              "      <td>5.7731</td>\n",
              "      <td>4.3721</td>\n",
              "      <td>4.3323</td>\n",
              "      <td>3.3700</td>\n",
              "      <td>4.1586</td>\n",
              "      <td>2.9777</td>\n",
              "      <td>3.7043</td>\n",
              "      <td>3.3220</td>\n",
              "      <td>4.8997</td>\n",
              "      <td>10.4640</td>\n",
              "      <td>5.9874</td>\n",
              "      <td>5.5031</td>\n",
              "      <td>5.4487</td>\n",
              "      <td>4.6683</td>\n",
              "      <td>5.2479</td>\n",
              "      <td>2.7686</td>\n",
              "      <td>5.5029</td>\n",
              "      <td>2.5728</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>3.3181</td>\n",
              "      <td>1.8862</td>\n",
              "      <td>3.0522</td>\n",
              "      <td>5.6869</td>\n",
              "      <td>3.9262</td>\n",
              "      <td>3.7255</td>\n",
              "      <td>3.2019</td>\n",
              "      <td>2.4177</td>\n",
              "      <td>3.4896</td>\n",
              "      <td>4.3090</td>\n",
              "      <td>3.6425</td>\n",
              "      <td>3.6585</td>\n",
              "      <td>3.8694</td>\n",
              "      <td>-1.6094</td>\n",
              "      <td>1.9041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A4GALT</th>\n",
              "      <td>5.6105</td>\n",
              "      <td>6.1484</td>\n",
              "      <td>5.6033</td>\n",
              "      <td>4.8897</td>\n",
              "      <td>6.3582</td>\n",
              "      <td>4.1105</td>\n",
              "      <td>6.0339</td>\n",
              "      <td>5.5600</td>\n",
              "      <td>6.3141</td>\n",
              "      <td>6.5725</td>\n",
              "      <td>5.8252</td>\n",
              "      <td>5.8368</td>\n",
              "      <td>6.5333</td>\n",
              "      <td>5.8638</td>\n",
              "      <td>6.3945</td>\n",
              "      <td>4.9704</td>\n",
              "      <td>5.7142</td>\n",
              "      <td>3.6112</td>\n",
              "      <td>3.9370</td>\n",
              "      <td>4.8622</td>\n",
              "      <td>5.9748</td>\n",
              "      <td>6.6621</td>\n",
              "      <td>5.8187</td>\n",
              "      <td>6.0738</td>\n",
              "      <td>4.0922</td>\n",
              "      <td>6.3132</td>\n",
              "      <td>6.2354</td>\n",
              "      <td>6.1071</td>\n",
              "      <td>5.7738</td>\n",
              "      <td>6.2654</td>\n",
              "      <td>4.6402</td>\n",
              "      <td>7.4740</td>\n",
              "      <td>6.3732</td>\n",
              "      <td>6.4837</td>\n",
              "      <td>6.7007</td>\n",
              "      <td>5.6885</td>\n",
              "      <td>5.0555</td>\n",
              "      <td>5.8974</td>\n",
              "      <td>6.4425</td>\n",
              "      <td>6.4981</td>\n",
              "      <td>...</td>\n",
              "      <td>5.6531</td>\n",
              "      <td>6.1260</td>\n",
              "      <td>3.3992</td>\n",
              "      <td>4.0354</td>\n",
              "      <td>6.7861</td>\n",
              "      <td>5.5619</td>\n",
              "      <td>5.9319</td>\n",
              "      <td>6.3026</td>\n",
              "      <td>4.9445</td>\n",
              "      <td>5.9085</td>\n",
              "      <td>5.9260</td>\n",
              "      <td>5.0305</td>\n",
              "      <td>5.8070</td>\n",
              "      <td>5.4364</td>\n",
              "      <td>6.0995</td>\n",
              "      <td>6.9477</td>\n",
              "      <td>7.0575</td>\n",
              "      <td>5.9649</td>\n",
              "      <td>5.1860</td>\n",
              "      <td>6.1117</td>\n",
              "      <td>6.1930</td>\n",
              "      <td>5.7755</td>\n",
              "      <td>5.5029</td>\n",
              "      <td>3.7490</td>\n",
              "      <td>7.9195</td>\n",
              "      <td>6.4010</td>\n",
              "      <td>5.9770</td>\n",
              "      <td>5.6764</td>\n",
              "      <td>5.5385</td>\n",
              "      <td>6.0449</td>\n",
              "      <td>4.8632</td>\n",
              "      <td>5.7265</td>\n",
              "      <td>5.3779</td>\n",
              "      <td>6.3920</td>\n",
              "      <td>5.9302</td>\n",
              "      <td>6.5048</td>\n",
              "      <td>6.1289</td>\n",
              "      <td>6.1716</td>\n",
              "      <td>6.7153</td>\n",
              "      <td>5.6827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 234 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        RR057e_00253  RR057e_00231  ...  RR057e_00116  RR057i_00078\n",
              "A1BG          3.3895        4.3247  ...        2.7813        3.0524\n",
              "A1CF          1.7220        2.6350  ...       -1.6094        1.2718\n",
              "A2M           5.5584        5.0045  ...        5.6167        5.1468\n",
              "A2ML1         2.9553        4.1445  ...       -1.6094        1.9041\n",
              "A4GALT        5.6105        6.1484  ...        6.7153        5.6827\n",
              "\n",
              "[5 rows x 234 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phD-eJKNG3Le",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64057d2e-67a3-4570-ac8d-8c2e74efbbdd"
      },
      "source": [
        "selected = ge.iloc[lasso_selections]\n",
        "selected.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 234)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Ai3vqXHpsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f86944a-334c-4665-ee72-de87b1df9580"
      },
      "source": [
        "selected.index.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ADAT3', 'ALOX15B', 'BACE2', 'BEST4', 'CACNA1E', 'CALHM6',\n",
              "       'CCDC81', 'CCL8', 'CD1E', 'CD163L1', 'CEMIP', 'CLCA2', 'CLEC10A',\n",
              "       'CPNE5', 'CRLF1', 'CXCL9', 'CXCL10', 'DGKI', 'DTL', 'DUOXA2',\n",
              "       'ECT2L', 'EIF3CL', 'ERVMER34-1', 'ESR1', 'FAM71A', 'FCGR1B',\n",
              "       'FOXO3B', 'GLI2', 'GOLGA6L1', 'GOLGA8N', 'GPR84', 'GRIN2B',\n",
              "       'GSTA2', 'GSTM1', 'GZMB', 'H2AC18', 'H3C4', 'HLA-DQA2', 'ICAM4',\n",
              "       'IFI6', 'IFI44L', 'IGLL5', 'IL1R2', 'KCNC4', 'KCNH7', 'KLHDC8A',\n",
              "       'LGI1', 'LGR6', 'LIMS2', 'LPAR4', 'MAP1B', 'MESP1', 'MMP19',\n",
              "       'MRC1', 'MS4A1', 'MUC2', 'MUC19', 'MYO1H', 'NRCAM', 'P3H4',\n",
              "       'PCSK5', 'PDGFRB', 'PERM1', 'RGPD2', 'RHCG', 'RIMBP3B', 'RIMBP3C',\n",
              "       'SCGB3A1', 'SIX5', 'SLC23A1', 'SPECC1L-ADORA2A', 'STATH', 'TGM3',\n",
              "       'TMEM63C', 'TMPRSS9', 'TNS3', 'TRO', 'UTY', 'WDR74', 'ZFP91-CNTF'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RViAUQwdKUnU"
      },
      "source": [
        "From searching through MSIGDB and the 60 resulting overlaps, I did not find a lot of gene sets that were related to the respiratory system or diseases. However, the second hit on the database (BOSCO_TH1_CYTOTOXIC_MODULE) was a gene with 7 genes overlap that represented Th1 / cytotoxic module in sputnum during asthma exacerbations, which is exactly what the question asks for. Another gene set that was close to a top hit, with 7 genes in overlap, is BLANCO_MELO_COVID19_SARS_COV_2_POS_PAT_PATIENT_LUNG_TISSUE_UP, which is a gene strongly upregulated in the lung tissue of post-mortem COVID-19 vs uninfected. Other genes involve diseases such as cancers (mainly breast cancer), human embryonic stem cell proteins, leukemia, and/or dendritic cells. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN_hp3HwC3Hv"
      },
      "source": [
        "### Training a COVID-19 infection classifier using AutoML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qeSQp0sC_tj"
      },
      "source": [
        "Train a multi-class classification model using AutoGluon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d5QNv1MLlps"
      },
      "source": [
        "#======================================================================\n",
        "# Train a classification model using AutoGluon TabularPrediction module\n",
        "from autogluon import TabularPrediction as task\n",
        "#======================================================================"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymfcdc_fDSoA"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred_score = lassocv.predict(x_test)\n",
        "y_pred_score = (np.exp(y_pred_score).T / np.exp(y_pred_score).sum(axis=1)).T\n",
        "y_pred = y_pred_score.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANB4CKBR-HDJ"
      },
      "source": [
        "gene_idx = (lassocv.coef_ != 0).sum(axis=0) != 0\n",
        "\n",
        "# Create training data using only the selected genes\n",
        "train_data = task.Dataset(x_train.loc[:, gene_idx].copy())\n",
        "train_data[\"disease_state\"] = meta.loc[meta.subset == \"train\",\n",
        "                                     \"disease_state\"].values\n",
        "label_column = \"disease_state\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhIzH-gWDSbe"
      },
      "source": [
        "Once the model is trained, I can evaluate my model using performance scores \n",
        "from class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX61Jmf_68ep"
      },
      "source": [
        "from sklearn.metrics import (accuracy_score, balanced_accuracy_score, \n",
        "                             roc_auc_score, f1_score)\n",
        "def performance_scores(y_true, y_pred_score, y_pred=None):\n",
        "    # We can find which class has the highest score as its predicted class\n",
        "    if y_pred is None:\n",
        "        y_pred = y_pred_score.argmax(axis=1)\n",
        "        \n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
        "        \"auroc\": roc_auc_score(y_true, y_pred_score, average=\"weighted\",\n",
        "                               multi_class=\"ovr\"),\n",
        "        \"f1\": f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ-DHUS0LqFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332f5bad-9c84-4d2e-ddb7-3cb5d2081bca"
      },
      "source": [
        "#===========================================================\n",
        "# Calculate the multi-class performance scores of your model\n",
        "\n",
        "predictor = task.fit(train_data=train_data, label=label_column,\n",
        "                     presets=\"good_quality_faster_inference_only_refit\",\n",
        "                     output_directory=\"good_quality\")\n",
        "#==========================================================="
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to good_quality/\n",
            "AutoGluon Version:  0.0.14\n",
            "Train Data Rows:    187\n",
            "Train Data Columns: 80\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t3 unique label values:  ['other virus', 'no virus', 'SC2']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "NumExpr defaulting to 2 threads.\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12597.66 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.12 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 80 | ['ADAT3', 'ALOX15B', 'BACE2', 'BEST4', 'CACNA1E', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 80 | ['ADAT3', 'ALOX15B', 'BACE2', 'BEST4', 'CACNA1E', ...]\n",
            "\t0.1s = Fit runtime\n",
            "\t80 features in original data used to generate 80 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.12 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.22s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
            "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
            "\t0.9198\t = Validation accuracy score\n",
            "\t7.29s\t = Training runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
            "\t0.861\t = Validation accuracy score\n",
            "\t3.66s\t = Training runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
            "\t0.8717\t = Validation accuracy score\n",
            "\t4.16s\t = Training runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
            "\t0.8824\t = Validation accuracy score\n",
            "\t3.03s\t = Training runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
            "\t0.8877\t = Validation accuracy score\n",
            "\t3.14s\t = Training runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
            "\t0.8824\t = Validation accuracy score\n",
            "\t1.59s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMClassifierXT_STACKER_l0 ...\n",
            "\t0.9144\t = Validation accuracy score\n",
            "\t1.27s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
            "\t0.8556\t = Validation accuracy score\n",
            "\t24.36s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
            "\t0.8289\t = Validation accuracy score\n",
            "\t7.94s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: weighted_ensemble_k0_l1 ...\n",
            "\t0.9251\t = Validation accuracy score\n",
            "\t0.23s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 59.33s ...\n",
            "Fitting model: NeuralNetClassifier_FULL_STACKER_l0 ...\n",
            "\t0.37s\t = Training runtime\n",
            "Fitting model: RandomForestClassifierGini_FULL_STACKER_l0 ...\n",
            "\t0.73s\t = Training runtime\n",
            "Fitting model: RandomForestClassifierEntr_FULL_STACKER_l0 ...\n",
            "\t0.84s\t = Training runtime\n",
            "Fitting model: ExtraTreesClassifierGini_FULL_STACKER_l0 ...\n",
            "\t0.64s\t = Training runtime\n",
            "Fitting model: ExtraTreesClassifierEntr_FULL_STACKER_l0 ...\n",
            "\t0.63s\t = Training runtime\n",
            "Fitting model: LightGBMClassifier_FULL_STACKER_l0 ...\n",
            "\t0.18s\t = Training runtime\n",
            "Fitting model: LightGBMClassifierXT_FULL_STACKER_l0 ...\n",
            "\t0.17s\t = Training runtime\n",
            "Fitting model: CatboostClassifier_FULL_STACKER_l0 ...\n",
            "\t1.31s\t = Training runtime\n",
            "Fitting model: LightGBMClassifierCustom_FULL_STACKER_l0 ...\n",
            "\t0.92s\t = Training runtime\n",
            "Fitting model: weighted_ensemble_FULL_k0_l1 ...\n",
            "\t0.9251\t = Validation accuracy score\n",
            "\t0.01s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89cNgKtTBtTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4f1a6b-31f4-4090-ec00-62b3b3321da7"
      },
      "source": [
        "predictor.fit_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                                         model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0                      weighted_ensemble_k0_l1   0.925134       0.615602  19.616512                0.000592           0.227520            1      False         10\n",
            "1               NeuralNetClassifier_STACKER_l0   0.919786       0.086188   7.287868                0.086188           7.287868            0      False          1\n",
            "2              LightGBMClassifierXT_STACKER_l0   0.914439       0.013783   1.266207                0.013783           1.266207            0      False          7\n",
            "3          ExtraTreesClassifierEntr_STACKER_l0   0.887701       0.511973   3.136584                0.511973           3.136584            0      False          5\n",
            "4                LightGBMClassifier_STACKER_l0   0.882353       0.013131   1.590834                0.013131           1.590834            0      False          6\n",
            "5          ExtraTreesClassifierGini_STACKER_l0   0.882353       0.511611   3.032108                0.511611           3.032108            0      False          4\n",
            "6        RandomForestClassifierEntr_STACKER_l0   0.871658       0.512295   4.162470                0.512295           4.162470            0      False          3\n",
            "7        RandomForestClassifierGini_STACKER_l0   0.860963       0.511804   3.663051                0.511804           3.663051            0      False          2\n",
            "8                CatboostClassifier_STACKER_l0   0.855615       0.017042  24.361558                0.017042          24.361558            0      False          8\n",
            "9          LightGBMClassifierCustom_STACKER_l0   0.828877       0.016528   7.938654                0.016528           7.938654            0      False          9\n",
            "10                weighted_ensemble_FULL_k0_l1        NaN            NaN   2.135760                0.000547           0.009657            1       True         20\n",
            "11  RandomForestClassifierGini_FULL_STACKER_l0        NaN            NaN   0.734823                     NaN           0.734823            0       True         12\n",
            "12  RandomForestClassifierEntr_FULL_STACKER_l0        NaN            NaN   0.836942                     NaN           0.836942            0       True         13\n",
            "13         NeuralNetClassifier_FULL_STACKER_l0        NaN            NaN   0.366530                     NaN           0.366530            0       True         11\n",
            "14          LightGBMClassifier_FULL_STACKER_l0        NaN            NaN   0.184504                     NaN           0.184504            0       True         16\n",
            "15        LightGBMClassifierXT_FULL_STACKER_l0        NaN            NaN   0.171223                     NaN           0.171223            0       True         17\n",
            "16    LightGBMClassifierCustom_FULL_STACKER_l0        NaN            NaN   0.922631                     NaN           0.922631            0       True         19\n",
            "17    ExtraTreesClassifierGini_FULL_STACKER_l0        NaN            NaN   0.637443                     NaN           0.637443            0       True         14\n",
            "18    ExtraTreesClassifierEntr_FULL_STACKER_l0        NaN            NaN   0.632840                     NaN           0.632840            0       True         15\n",
            "19          CatboostClassifier_FULL_STACKER_l0        NaN            NaN   1.314709                     NaN           1.314709            0       True         18\n",
            "Number of models trained: 20\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_RF', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_XT', 'WeightedEnsembleModel', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_Catboost'}\n",
            "Bagging used: True  (with 5 folds)\n",
            "Stack-ensembling used: False \n",
            "Hyperparameter-tuning used: False \n",
            "User-specified hyperparameters:\n",
            "{'default': {'NN': [{}], 'GBM': [{}, {'extra_trees': True, 'AG_args': {'name_suffix': 'XT'}}], 'CAT': [{}], 'RF': [{'criterion': 'gini', 'max_depth': 15, 'AG_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'AG_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}], 'XT': [{'criterion': 'gini', 'max_depth': 15, 'AG_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'AG_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}], 'custom': [{'num_boost_round': 10000, 'num_threads': -1, 'objective': 'multiclass', 'num_classes': 3, 'verbose': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'two_round': True, 'seed_value': 0, 'AG_args': {'model_type': 'GBM', 'name_suffix': 'Custom', 'disable_in_hpo': True}}]}}\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', []) : 80 | ['ADAT3', 'ALOX15B', 'BACE2', 'BEST4', 'CACNA1E', ...]\n",
            "Plot summary of models saved to file: good_quality/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'feature_prune': False,\n",
              " 'hyperparameter_tune': False,\n",
              " 'hyperparameters_userspecified': {'default': {'CAT': [{}],\n",
              "   'GBM': [{}, {'AG_args': {'name_suffix': 'XT'}, 'extra_trees': True}],\n",
              "   'NN': [{}],\n",
              "   'RF': [{'AG_args': {'name_suffix': 'Gini',\n",
              "      'problem_types': ['binary', 'multiclass']},\n",
              "     'criterion': 'gini',\n",
              "     'max_depth': 15},\n",
              "    {'AG_args': {'name_suffix': 'Entr',\n",
              "      'problem_types': ['binary', 'multiclass']},\n",
              "     'criterion': 'entropy',\n",
              "     'max_depth': 15}],\n",
              "   'XT': [{'AG_args': {'name_suffix': 'Gini',\n",
              "      'problem_types': ['binary', 'multiclass']},\n",
              "     'criterion': 'gini',\n",
              "     'max_depth': 15},\n",
              "    {'AG_args': {'name_suffix': 'Entr',\n",
              "      'problem_types': ['binary', 'multiclass']},\n",
              "     'criterion': 'entropy',\n",
              "     'max_depth': 15}],\n",
              "   'custom': [{'AG_args': {'disable_in_hpo': True,\n",
              "      'model_type': 'GBM',\n",
              "      'name_suffix': 'Custom'},\n",
              "     'boosting_type': 'gbdt',\n",
              "     'feature_fraction': 0.9,\n",
              "     'learning_rate': 0.03,\n",
              "     'min_data_in_leaf': 3,\n",
              "     'num_boost_round': 10000,\n",
              "     'num_classes': 3,\n",
              "     'num_leaves': 128,\n",
              "     'num_threads': -1,\n",
              "     'objective': 'multiclass',\n",
              "     'seed_value': 0,\n",
              "     'two_round': True,\n",
              "     'verbose': -1}]}},\n",
              " 'leaderboard':                                          model  score_val  ...  can_infer  fit_order\n",
              " 0                      weighted_ensemble_k0_l1   0.925134  ...      False         10\n",
              " 1               NeuralNetClassifier_STACKER_l0   0.919786  ...      False          1\n",
              " 2              LightGBMClassifierXT_STACKER_l0   0.914439  ...      False          7\n",
              " 3          ExtraTreesClassifierEntr_STACKER_l0   0.887701  ...      False          5\n",
              " 4                LightGBMClassifier_STACKER_l0   0.882353  ...      False          6\n",
              " 5          ExtraTreesClassifierGini_STACKER_l0   0.882353  ...      False          4\n",
              " 6        RandomForestClassifierEntr_STACKER_l0   0.871658  ...      False          3\n",
              " 7        RandomForestClassifierGini_STACKER_l0   0.860963  ...      False          2\n",
              " 8                CatboostClassifier_STACKER_l0   0.855615  ...      False          8\n",
              " 9          LightGBMClassifierCustom_STACKER_l0   0.828877  ...      False          9\n",
              " 10                weighted_ensemble_FULL_k0_l1        NaN  ...       True         20\n",
              " 11  RandomForestClassifierGini_FULL_STACKER_l0        NaN  ...       True         12\n",
              " 12  RandomForestClassifierEntr_FULL_STACKER_l0        NaN  ...       True         13\n",
              " 13         NeuralNetClassifier_FULL_STACKER_l0        NaN  ...       True         11\n",
              " 14          LightGBMClassifier_FULL_STACKER_l0        NaN  ...       True         16\n",
              " 15        LightGBMClassifierXT_FULL_STACKER_l0        NaN  ...       True         17\n",
              " 16    LightGBMClassifierCustom_FULL_STACKER_l0        NaN  ...       True         19\n",
              " 17    ExtraTreesClassifierGini_FULL_STACKER_l0        NaN  ...       True         14\n",
              " 18    ExtraTreesClassifierEntr_FULL_STACKER_l0        NaN  ...       True         15\n",
              " 19          CatboostClassifier_FULL_STACKER_l0        NaN  ...       True         18\n",
              " \n",
              " [20 rows x 9 columns],\n",
              " 'model_best': 'weighted_ensemble_FULL_k0_l1',\n",
              " 'model_fit_times': {'CatboostClassifier_FULL_STACKER_l0': 1.3147094249725342,\n",
              "  'CatboostClassifier_STACKER_l0': 24.361558198928833,\n",
              "  'ExtraTreesClassifierEntr_FULL_STACKER_l0': 0.6328396797180176,\n",
              "  'ExtraTreesClassifierEntr_STACKER_l0': 3.1365840435028076,\n",
              "  'ExtraTreesClassifierGini_FULL_STACKER_l0': 0.6374428272247314,\n",
              "  'ExtraTreesClassifierGini_STACKER_l0': 3.0321080684661865,\n",
              "  'LightGBMClassifierCustom_FULL_STACKER_l0': 0.922630786895752,\n",
              "  'LightGBMClassifierCustom_STACKER_l0': 7.938653945922852,\n",
              "  'LightGBMClassifierXT_FULL_STACKER_l0': 0.17122268676757812,\n",
              "  'LightGBMClassifierXT_STACKER_l0': 1.266207218170166,\n",
              "  'LightGBMClassifier_FULL_STACKER_l0': 0.18450379371643066,\n",
              "  'LightGBMClassifier_STACKER_l0': 1.5908336639404297,\n",
              "  'NeuralNetClassifier_FULL_STACKER_l0': 0.366530179977417,\n",
              "  'NeuralNetClassifier_STACKER_l0': 7.287868499755859,\n",
              "  'RandomForestClassifierEntr_FULL_STACKER_l0': 0.8369424343109131,\n",
              "  'RandomForestClassifierEntr_STACKER_l0': 4.162469863891602,\n",
              "  'RandomForestClassifierGini_FULL_STACKER_l0': 0.7348232269287109,\n",
              "  'RandomForestClassifierGini_STACKER_l0': 3.663050889968872,\n",
              "  'weighted_ensemble_FULL_k0_l1': 0.009656667709350586,\n",
              "  'weighted_ensemble_k0_l1': 0.22751951217651367},\n",
              " 'model_hyperparams': {'CatboostClassifier_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'CatboostClassifier_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'ExtraTreesClassifierEntr_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'ExtraTreesClassifierEntr_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'ExtraTreesClassifierGini_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'ExtraTreesClassifierGini_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'LightGBMClassifierCustom_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'LightGBMClassifierCustom_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'LightGBMClassifierXT_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'LightGBMClassifierXT_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'LightGBMClassifier_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'LightGBMClassifier_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'NeuralNetClassifier_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'NeuralNetClassifier_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'RandomForestClassifierEntr_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'RandomForestClassifierEntr_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'RandomForestClassifierGini_FULL_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'RandomForestClassifierGini_STACKER_l0': {'max_models': 25,\n",
              "   'max_models_per_type': 5},\n",
              "  'weighted_ensemble_FULL_k0_l1': {'max_models': 25, 'max_models_per_type': 5},\n",
              "  'weighted_ensemble_k0_l1': {'max_models': 25, 'max_models_per_type': 5}},\n",
              " 'model_paths': {'CatboostClassifier_FULL_STACKER_l0': 'good_quality/models/CatboostClassifier_FULL_STACKER_l0/',\n",
              "  'CatboostClassifier_STACKER_l0': 'good_quality/models/CatboostClassifier_STACKER_l0/',\n",
              "  'ExtraTreesClassifierEntr_FULL_STACKER_l0': 'good_quality/models/ExtraTreesClassifierEntr_FULL_STACKER_l0/',\n",
              "  'ExtraTreesClassifierEntr_STACKER_l0': 'good_quality/models/ExtraTreesClassifierEntr_STACKER_l0/',\n",
              "  'ExtraTreesClassifierGini_FULL_STACKER_l0': 'good_quality/models/ExtraTreesClassifierGini_FULL_STACKER_l0/',\n",
              "  'ExtraTreesClassifierGini_STACKER_l0': 'good_quality/models/ExtraTreesClassifierGini_STACKER_l0/',\n",
              "  'LightGBMClassifierCustom_FULL_STACKER_l0': 'good_quality/models/LightGBMClassifierCustom_FULL_STACKER_l0/',\n",
              "  'LightGBMClassifierCustom_STACKER_l0': 'good_quality/models/LightGBMClassifierCustom_STACKER_l0/',\n",
              "  'LightGBMClassifierXT_FULL_STACKER_l0': 'good_quality/models/LightGBMClassifierXT_FULL_STACKER_l0/',\n",
              "  'LightGBMClassifierXT_STACKER_l0': 'good_quality/models/LightGBMClassifierXT_STACKER_l0/',\n",
              "  'LightGBMClassifier_FULL_STACKER_l0': 'good_quality/models/LightGBMClassifier_FULL_STACKER_l0/',\n",
              "  'LightGBMClassifier_STACKER_l0': 'good_quality/models/LightGBMClassifier_STACKER_l0/',\n",
              "  'NeuralNetClassifier_FULL_STACKER_l0': 'good_quality/models/NeuralNetClassifier_FULL_STACKER_l0/',\n",
              "  'NeuralNetClassifier_STACKER_l0': 'good_quality/models/NeuralNetClassifier_STACKER_l0/',\n",
              "  'RandomForestClassifierEntr_FULL_STACKER_l0': 'good_quality/models/RandomForestClassifierEntr_FULL_STACKER_l0/',\n",
              "  'RandomForestClassifierEntr_STACKER_l0': 'good_quality/models/RandomForestClassifierEntr_STACKER_l0/',\n",
              "  'RandomForestClassifierGini_FULL_STACKER_l0': 'good_quality/models/RandomForestClassifierGini_FULL_STACKER_l0/',\n",
              "  'RandomForestClassifierGini_STACKER_l0': 'good_quality/models/RandomForestClassifierGini_STACKER_l0/',\n",
              "  'weighted_ensemble_FULL_k0_l1': 'good_quality/models/weighted_ensemble_FULL_k0_l1/',\n",
              "  'weighted_ensemble_k0_l1': 'good_quality/models/weighted_ensemble_k0_l1/'},\n",
              " 'model_performance': {'CatboostClassifier_FULL_STACKER_l0': None,\n",
              "  'CatboostClassifier_STACKER_l0': 0.8556149732620321,\n",
              "  'ExtraTreesClassifierEntr_FULL_STACKER_l0': None,\n",
              "  'ExtraTreesClassifierEntr_STACKER_l0': 0.8877005347593583,\n",
              "  'ExtraTreesClassifierGini_FULL_STACKER_l0': None,\n",
              "  'ExtraTreesClassifierGini_STACKER_l0': 0.8823529411764706,\n",
              "  'LightGBMClassifierCustom_FULL_STACKER_l0': None,\n",
              "  'LightGBMClassifierCustom_STACKER_l0': 0.8288770053475936,\n",
              "  'LightGBMClassifierXT_FULL_STACKER_l0': None,\n",
              "  'LightGBMClassifierXT_STACKER_l0': 0.9144385026737968,\n",
              "  'LightGBMClassifier_FULL_STACKER_l0': None,\n",
              "  'LightGBMClassifier_STACKER_l0': 0.8823529411764706,\n",
              "  'NeuralNetClassifier_FULL_STACKER_l0': None,\n",
              "  'NeuralNetClassifier_STACKER_l0': 0.9197860962566845,\n",
              "  'RandomForestClassifierEntr_FULL_STACKER_l0': None,\n",
              "  'RandomForestClassifierEntr_STACKER_l0': 0.8716577540106952,\n",
              "  'RandomForestClassifierGini_FULL_STACKER_l0': None,\n",
              "  'RandomForestClassifierGini_STACKER_l0': 0.8609625668449198,\n",
              "  'weighted_ensemble_FULL_k0_l1': None,\n",
              "  'weighted_ensemble_k0_l1': 0.9251336898395722},\n",
              " 'model_pred_times': {'CatboostClassifier_FULL_STACKER_l0': None,\n",
              "  'CatboostClassifier_STACKER_l0': 0.017041683197021484,\n",
              "  'ExtraTreesClassifierEntr_FULL_STACKER_l0': None,\n",
              "  'ExtraTreesClassifierEntr_STACKER_l0': 0.5119729042053223,\n",
              "  'ExtraTreesClassifierGini_FULL_STACKER_l0': None,\n",
              "  'ExtraTreesClassifierGini_STACKER_l0': 0.5116114616394043,\n",
              "  'LightGBMClassifierCustom_FULL_STACKER_l0': None,\n",
              "  'LightGBMClassifierCustom_STACKER_l0': 0.01652836799621582,\n",
              "  'LightGBMClassifierXT_FULL_STACKER_l0': None,\n",
              "  'LightGBMClassifierXT_STACKER_l0': 0.01378321647644043,\n",
              "  'LightGBMClassifier_FULL_STACKER_l0': None,\n",
              "  'LightGBMClassifier_STACKER_l0': 0.013130664825439453,\n",
              "  'NeuralNetClassifier_FULL_STACKER_l0': None,\n",
              "  'NeuralNetClassifier_STACKER_l0': 0.08618783950805664,\n",
              "  'RandomForestClassifierEntr_FULL_STACKER_l0': None,\n",
              "  'RandomForestClassifierEntr_STACKER_l0': 0.5122947692871094,\n",
              "  'RandomForestClassifierGini_FULL_STACKER_l0': None,\n",
              "  'RandomForestClassifierGini_STACKER_l0': 0.5118043422698975,\n",
              "  'weighted_ensemble_FULL_k0_l1': 0.0005469322204589844,\n",
              "  'weighted_ensemble_k0_l1': 0.0005915164947509766},\n",
              " 'model_types': {'CatboostClassifier_FULL_STACKER_l0': 'StackerEnsembleModel_Catboost',\n",
              "  'CatboostClassifier_STACKER_l0': 'StackerEnsembleModel_Catboost',\n",
              "  'ExtraTreesClassifierEntr_FULL_STACKER_l0': 'StackerEnsembleModel_XT',\n",
              "  'ExtraTreesClassifierEntr_STACKER_l0': 'StackerEnsembleModel_XT',\n",
              "  'ExtraTreesClassifierGini_FULL_STACKER_l0': 'StackerEnsembleModel_XT',\n",
              "  'ExtraTreesClassifierGini_STACKER_l0': 'StackerEnsembleModel_XT',\n",
              "  'LightGBMClassifierCustom_FULL_STACKER_l0': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBMClassifierCustom_STACKER_l0': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBMClassifierXT_FULL_STACKER_l0': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBMClassifierXT_STACKER_l0': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBMClassifier_FULL_STACKER_l0': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBMClassifier_STACKER_l0': 'StackerEnsembleModel_LGB',\n",
              "  'NeuralNetClassifier_FULL_STACKER_l0': 'StackerEnsembleModel_TabularNeuralNet',\n",
              "  'NeuralNetClassifier_STACKER_l0': 'StackerEnsembleModel_TabularNeuralNet',\n",
              "  'RandomForestClassifierEntr_FULL_STACKER_l0': 'StackerEnsembleModel_RF',\n",
              "  'RandomForestClassifierEntr_STACKER_l0': 'StackerEnsembleModel_RF',\n",
              "  'RandomForestClassifierGini_FULL_STACKER_l0': 'StackerEnsembleModel_RF',\n",
              "  'RandomForestClassifierGini_STACKER_l0': 'StackerEnsembleModel_RF',\n",
              "  'weighted_ensemble_FULL_k0_l1': 'WeightedEnsembleModel',\n",
              "  'weighted_ensemble_k0_l1': 'WeightedEnsembleModel'},\n",
              " 'num_bagging_folds': 5,\n",
              " 'num_classes': 3,\n",
              " 'stack_ensemble_levels': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkscKm_3_jt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd39a24-799a-4ae7-848a-49fa96c9d3d8"
      },
      "source": [
        "test_data = task.Dataset(x_test.loc[:,gene_idx].copy())\n",
        "y_pred_score = predictor.predict_proba(test_data)\n",
        "performance_scores(y_test.argmax(axis=1), y_pred_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8297872340425532,\n",
              " 'auroc': 0.9038309995756804,\n",
              " 'balanced_accuracy': 0.7407894736842104,\n",
              " 'f1': 0.8136778115501521}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd5wOCKBLuZa"
      },
      "source": [
        "I can also calculate scores if I only consider whether the sample is infected by SC2 or not, similar to what was done in class for cancer vs normal prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77zGI1_ILxKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce2f3b6-5b68-481b-a9b7-6f7a2b77a41f"
      },
      "source": [
        "#===========================================================================\n",
        "# Calculate the binary performance scores of your model considering only SC2\n",
        "# vs non-SC2\n",
        "y_test_bin = (y_test[:, encoder.categories_[0] == \"SC2\"] == 1).flatten().astype(int)\n",
        "y_pred_score_bin = y_pred_score[:, encoder.categories_[0] == \"SC2\"]\n",
        "y_pred_bin = (y_pred == (encoder.categories_[0] == \"SC2\").argmax()).astype(int)\n",
        "performance_scores(y_test_bin, y_pred_score_bin, y_pred=y_pred_bin)\n",
        "#==========================================================================="
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8936170212765957,\n",
              " 'auroc': 0.9210526315789475,\n",
              " 'balanced_accuracy': 0.893796992481203,\n",
              " 'f1': 0.894013787630809}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmpaGzJZNLGa"
      },
      "source": [
        "When it is a binary model then the accuracies are easier to achieve higher values as shown here, where both accuracy and balanced accuracy are improved from original.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxEow15-Lyvq"
      },
      "source": [
        "Now I can also plot a confusion matrix to show correct and incorrect predictions in three classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlXbwYzNL01F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "8cdb09fa-46de-42a3-9cb7-2d13de64c0eb"
      },
      "source": [
        "#============================================\n",
        "# Plot confusion matrix for all three classes\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test.argmax(axis=1),\n",
        "                      y_pred_score.argmax(axis=1))\n",
        "\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels = encoder.categories[0])\n",
        "disp.plot(cmap = \"Blues\")\n",
        "#============================================"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f35988fbb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}